{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation:\n",
    "An online source where skaters communications with each other is openly displayed and recorded is youtube comments. Under skate videos many people interested in the contents will have discussions. While these comments are not reflective of speech they are indicative of the speech patterns and slang used by skateboarders interested in these videos. \n",
    "\n",
    "Because of the massive availiblity of public data in this domain I figured it was an excellent place to start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_packages = True\n",
    "delete_existing_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: selenium in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (4.19.0)\n",
      "Requirement already satisfied: pandas in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: google-api-python-client in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.125.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: google-auth-httplib2 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: trio~=0.17 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from selenium->-r requirements.txt (line 1)) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from selenium->-r requirements.txt (line 1)) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from selenium->-r requirements.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from selenium->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from google-api-python-client->-r requirements.txt (line 3)) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from google-api-python-client->-r requirements.txt (line 3)) (2.29.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from google-api-python-client->-r requirements.txt (line 3)) (2.18.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from google-api-python-client->-r requirements.txt (line 3)) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from google-auth-oauthlib->-r requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client->-r requirements.txt (line 3)) (1.63.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client->-r requirements.txt (line 3)) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client->-r requirements.txt (line 3)) (1.23.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client->-r requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client->-r requirements.txt (line 3)) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client->-r requirements.txt (line 3)) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client->-r requirements.txt (line 3)) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->-r requirements.txt (line 4)) (3.2.2)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: idna in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: outcome in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium->-r requirements.txt (line 1)) (1.7.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client->-r requirements.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client->-r requirements.txt (line 3)) (2.0.4)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/carter/.conda/envs/anth/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->-r requirements.txt (line 1)) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "if install_packages:\n",
    "    ! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import re\n",
    "import html\n",
    "import json\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if delete_existing_data:\n",
    "    try:\n",
    "        shutil.rmtree('./data')\n",
    "        shutil.rmtree('./meta')\n",
    "    except:\n",
    "        display(Markdown('### No such folder to delete!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping data:\n",
    "Thrasher will be the starting point for scraping this data. In order to do this I am using [simple-youtube-comment-crawler](https://github.com/hangyeoldora/Simple-Youtube-Comment-Downloader.git) to scrape comments from the internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Youtube API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"AIzaSyDrm4yGLK6uCcQI5ZlWVG3acRd4XvH0o3M\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_yt_video(video_id, max_results=50):\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    try:\n",
    "        # Retrieve comments for the given video ID\n",
    "        comments = []\n",
    "        next_page_token = None\n",
    "\n",
    "        while True:\n",
    "            response = youtube.commentThreads().list(\n",
    "                part='snippet',\n",
    "                videoId=video_id,\n",
    "                textFormat='plainText',\n",
    "                maxResults=max_results,\n",
    "                pageToken=next_page_token\n",
    "            ).execute()\n",
    "\n",
    "            # Collect comments\n",
    "            for item in response['items']:\n",
    "                comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "                comments.append(comment)\n",
    "\n",
    "            # Check if there are more comments to fetch\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "\n",
    "        return comments\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f'An HTTP error {e.resp.status} occurred: {e.content}')\n",
    "        return None\n",
    "\n",
    "def get_popular_yt_videos(channel_id, max_results=50):\n",
    "    # Initialize the YouTube Data API client\n",
    "    youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "    \n",
    "    pageToken = None\n",
    "\n",
    "\n",
    "    videos = []\n",
    "\n",
    "    try:\n",
    "        for page in range(0,max_results, 50):\n",
    "            # Retrieve most popular videos for the given channel\n",
    "            request = youtube.search().list(\n",
    "                part=\"snippet\",\n",
    "                channelId=channel_id,\n",
    "                type=\"video\",\n",
    "                order=\"viewCount\",\n",
    "                maxResults=max_results,\n",
    "                pageToken=pageToken\n",
    "            )\n",
    "\n",
    "\n",
    "            response = request.execute()\n",
    "\n",
    "            pageToken = response['nextPageToken']\n",
    "\n",
    "            for item in response[\"items\"]:\n",
    "                video_id = item[\"id\"][\"videoId\"]\n",
    "                title = item[\"snippet\"][\"title\"]\n",
    "                videos.append({\"title\": title, \"video_id\": video_id})\n",
    "    except:\n",
    "        return videos\n",
    "\n",
    "    return videos\n",
    "\n",
    "def get_video_metadata(video_id):\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    video_response = youtube.videos().list(\n",
    "        part='snippet,statistics',\n",
    "        id=video_id\n",
    "    ).execute()\n",
    "\n",
    "    video_details = video_response['items'][0]\n",
    "    snippet = video_details['snippet']\n",
    "    statistics = video_details['statistics']\n",
    "\n",
    "    metaData = dict()\n",
    "\n",
    "    metaData['Title'] = snippet['title']\n",
    "    metaData['Description'] = snippet['description']\n",
    "    metaData['Published'] = snippet['publishedAt']\n",
    "    metaData['Views'] = statistics['viewCount']\n",
    "    metaData['Likes'] = statistics['likeCount']\n",
    "    metaData['Comments'] = statistics['commentCount']\n",
    "    return metaData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a helper function to clean youtube titles into file-friendly strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(input_string):\n",
    "    cleaned_string = html.unescape(input_string)\n",
    "    cleaned_string = cleaned_string.lower()\n",
    "    cleaned_string = cleaned_string.replace(' ', '-')\n",
    "    cleaned_string = re.sub(r'[^a-zA-Z0-9\\-]', '', cleaned_string)\n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to find the most popular videos by Thrasher for our use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Video data allready pulled. Fetching from files**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thrasher_id = \"UCt16NSYjauKclK67LCXvQyA\"\n",
    "newschoolers_id = \"UC27MqEZBoxV0Cs7ZbMtBk1g\"\n",
    "\n",
    "popular_videos = dict()\n",
    "\n",
    "if os.path.exists('./videos'):\n",
    "    display(Markdown('**Video data allready pulled. Fetching from files**'))\n",
    "    for filename in os.listdir('./videos'):\n",
    "        with open(f'./videos/{filename}') as f:\n",
    "            popular_videos[os.path.splitext(filename)[0]] = json.loads(f.read())\n",
    "else:\n",
    "    os.mkdir('./videos')\n",
    "    videos_raw = get_popular_yt_videos(thrasher_id, 500)\n",
    "    for video in videos_raw:\n",
    "        filename = clean_string(video['title'])\n",
    "        popular_videos[filename] = video\n",
    "        with open(f'./videos/{filename}.json', 'w') as f:\n",
    "            f.write(json.dumps(video))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Video titles**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Total number:** 499"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- SKATELINE - Jamie Foy El Toro Front Krook War? Tom Schaar, Antonio Durao &amp; More"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- King of the Road 2012: Webisode 3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- &quot;Revolutions on Granite&quot; Ukraine Skate Documentary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- The Basement Tapes Marc Johnson"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- SKATELINE - Hit Makers Jereme Rogers &amp; Steven Fernandez, Erick Winkowski, Blake Johnson Pro"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Evan Smith&#39;s &quot;Sky Bird People Up-Jump&quot; Grimple Part"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- My War: Ryan Decenzo"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- King of the Road 2010: Episode 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Emerica&#39;s &quot;THIS&quot; Video"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- SKATELINE - Shane ONeill, Nick Tucker, Andrew Brophy, Marc Johnson, GX 1000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown('**Video titles**'))\n",
    "display(Markdown(f'**Total number:** {len(popular_videos)}'))\n",
    "for video in list(popular_videos.keys())[:10]:\n",
    "    display(Markdown(f'- {popular_videos[video]['title']}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Data allready exists, skipping scraping"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comments = dict()\n",
    "if os.path.exists('./data'):\n",
    "    display(Markdown('### Data allready exists, skipping scraping'))\n",
    "    for file in os.listdir('./data'):\n",
    "        with open(f'./data/{file}', 'r') as f:\n",
    "            comments[os.path.splitext(file)[0]] = f.readlines()\n",
    "else:\n",
    "    os.mkdir('./data')\n",
    "\n",
    "    for videoKey in popular_videos:\n",
    "        video = popular_videos[videoKey]\n",
    "        with open(f'./data/{clean_string(video['title'])}.txt', 'w') as f:\n",
    "            video_comments = get_comments_yt_video(video['video_id'])\n",
    "            f.writelines('%s\\n' % comment for comment in video_comments)\n",
    "            comments.append(video_comments)\n",
    "        display(Markdown(f'**{video['title']}** scraping complete'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get video metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Metadata allready exists: pulling in from files**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metaData = dict()\n",
    "if os.path.exists('./meta'): \n",
    "    display(Markdown('**Metadata allready exists: pulling in from files**'))\n",
    "    for metadata_file in os.listdir('./meta'):\n",
    "        with open(f'./meta/{metadata_file}', 'r') as f:\n",
    "            metaData[os.path.splitext(metadata_file)[0]] = json.loads(f.read())\n",
    "else: \n",
    "    os.mkdir('./meta')\n",
    "    for video in popular_videos:\n",
    "        videoFileName = clean_string(video['title'])\n",
    "        metaDataItem = get_video_metadata(video['video_id'])\n",
    "        with open(f'./meta/{videoFileName}.txt', 'w') as f:\n",
    "            f.write(json.dumps(metaDataItem))\n",
    "        metaData[videoFileName] = metaDataItem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative content analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patterns and trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare and contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://arxiv.org/pdf/1601.01126v1.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
